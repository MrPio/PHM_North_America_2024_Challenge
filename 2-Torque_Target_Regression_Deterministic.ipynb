{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-02T08:23:01.426938Z",
     "start_time": "2025-03-02T08:22:19.956882Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load dataset",
   "id": "b57242d665764f80"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T08:23:01.974317Z",
     "start_time": "2025-03-02T08:23:01.959278Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_dataset(train_x: torch.Tensor, train_y: torch.Tensor, test_size=0.3):\n",
    "    indices = torch.randperm(train_x.shape[0])\n",
    "    test_size = int(train_x.shape[0] * test_size)\n",
    "    test_indices, train_indices = indices[:test_size], indices[test_size:]\n",
    "    return {'train_input': train_x[train_indices].to(device), 'test_input': train_x[test_indices].to(device),\n",
    "            'train_label': train_y[train_indices].to(device), 'test_label': train_y[test_indices].to(device)}"
   ],
   "id": "c67062c073ebd6f8",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T08:23:03.232166Z",
     "start_time": "2025-03-02T08:23:01.992343Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Read the train set files \n",
    "df_x = pd.read_csv('dataset/X_train.csv').drop(columns=['id'])\n",
    "df_y = pd.read_csv('dataset/y_train.csv').drop(columns=['id', 'faulty'])\n",
    "df_y['trq_target'] = df_x['trq_measured'] / (df_y['trq_margin'] / 100 + 1)\n",
    "df_x_normalized = (df_x - df_x.mean()) / df_x.std()\n",
    "df_y_normalized = (df_y['trq_target'] - df_y['trq_target'].mean()) / df_y['trq_target'].std()\n",
    "df_x_normalized.drop(columns=['trq_measured'], inplace=True)\n",
    "\n",
    "train_x_1 = torch.tensor(df_x_normalized.values, dtype=torch.float32, device=device)\n",
    "train_y_1 = torch.tensor(df_y_normalized.values, dtype=torch.float32, device=device).unsqueeze(1)\n",
    "assert (train_x_1.shape[0] == train_y_1.shape[0])"
   ],
   "id": "c58876efec7eafae",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T08:23:03.530906Z",
     "start_time": "2025-03-02T08:23:03.469998Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Downsample to 10%\n",
    "random_indices = np.random.choice(train_x_1.shape[0], size=train_x_1.shape[0] // 10, replace=False)\n",
    "train_x_10 = train_x_1[random_indices]\n",
    "train_y_10 = train_y_1[random_indices]\n",
    "# Downsample to 1%\n",
    "random_indices = np.random.choice(train_x_1.shape[0], size=train_x_1.shape[0] // 100, replace=False)\n",
    "train_x_100 = train_x_1[random_indices]\n",
    "train_y_100 = train_y_1[random_indices]"
   ],
   "id": "66ff76bc2b090985",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T08:44:26.003021Z",
     "start_time": "2025-03-02T08:44:25.988872Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(model, optimizer, inputs: torch.Tensor, labels, epochs=5, batch_size=100, deterministic=False):\n",
    "    criterion_stochastic = nn.GaussianNLLLoss()\n",
    "    criterion_deterministic = nn.MSELoss()\n",
    "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        with tqdm(range(inputs.size(0) // batch_size)) as pbar:\n",
    "            for i in pbar:\n",
    "                x = inputs[i * batch_size:(i + 1) * batch_size].to(device)\n",
    "                y = labels[i * batch_size:(i + 1) * batch_size].to(device)\n",
    "                optimizer.zero_grad()\n",
    "                if deterministic:\n",
    "                    output = model(x)\n",
    "                    loss = criterion_deterministic(output, y)\n",
    "                else:\n",
    "                    mu, var = model(x)\n",
    "                    loss = criterion_stochastic(mu, y, var)\n",
    "                loss.backward()\n",
    "                optimizer.step(closure=lambda: loss)\n",
    "                pbar.set_postfix(loss=loss.item(), lr=optimizer.param_groups[0]['lr'])\n",
    "                scheduler.step()"
   ],
   "id": "8c791f8ed54ecd1a",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### MLP training",
   "id": "c45758c75340e0ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T08:42:25.509267Z",
     "start_time": "2025-03-02T08:42:25.493580Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, layers_size, deterministic=False):\n",
    "        super(MLP, self).__init__()\n",
    "        layers = []\n",
    "        for i in range(len(layers_size) - 1):\n",
    "            layers.append(nn.Linear(layers_size[i], layers_size[i + 1]))\n",
    "            if i < len(layers_size) - 2:  # Add activation for all layers except the last one\n",
    "                layers.append(nn.Sigmoid())\n",
    "        self.model = nn.Sequential(*layers)\n",
    "        self.deterministic = deterministic\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.model(x)\n",
    "        if self.deterministic:\n",
    "            return output\n",
    "        else:\n",
    "            mu = output[:, 0]\n",
    "            var = F.softplus(output[:, 1]) + 1e-6\n",
    "            return mu, var"
   ],
   "id": "9196b72f8ea42196",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T08:42:27.020376Z",
     "start_time": "2025-03-02T08:42:27.004473Z"
    }
   },
   "cell_type": "code",
   "source": "mlp = MLP([6, 256, 256, 1], deterministic=True).to(device)",
   "id": "e2d29fb417331c4b",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T08:44:44.199707Z",
     "start_time": "2025-03-02T08:44:32.462856Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train(mlp, optim.Adam(mlp.parameters(), lr=0.0004), train_x_10, train_y_10, epochs=50,\n",
    "      batch_size=1024, deterministic=True)"
   ],
   "id": "981f03ef2059776a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:00<00:00, 166.56it/s, loss=0.000323, lr=0.000373]\n",
      "100%|██████████| 72/72 [00:00<00:00, 321.93it/s, loss=0.000318, lr=0.000347]\n",
      "100%|██████████| 72/72 [00:00<00:00, 312.90it/s, loss=0.000315, lr=0.000323]\n",
      "100%|██████████| 72/72 [00:00<00:00, 329.93it/s, loss=0.00031, lr=0.0003]   \n",
      "100%|██████████| 72/72 [00:00<00:00, 323.61it/s, loss=0.000306, lr=0.000279]\n",
      "100%|██████████| 72/72 [00:00<00:00, 312.98it/s, loss=0.000301, lr=0.00026] \n",
      "100%|██████████| 72/72 [00:00<00:00, 327.26it/s, loss=0.000297, lr=0.000242]\n",
      "100%|██████████| 72/72 [00:00<00:00, 319.92it/s, loss=0.000293, lr=0.000225]\n",
      "100%|██████████| 72/72 [00:00<00:00, 339.72it/s, loss=0.000289, lr=0.000209]\n",
      "100%|██████████| 72/72 [00:00<00:00, 327.12it/s, loss=0.000285, lr=0.000195]\n",
      "100%|██████████| 72/72 [00:00<00:00, 313.00it/s, loss=0.000281, lr=0.000181]\n",
      "100%|██████████| 72/72 [00:00<00:00, 327.71it/s, loss=0.000278, lr=0.000169]\n",
      "100%|██████████| 72/72 [00:00<00:00, 318.57it/s, loss=0.000275, lr=0.000157]\n",
      "100%|██████████| 72/72 [00:00<00:00, 326.69it/s, loss=0.000272, lr=0.000146]\n",
      "100%|██████████| 72/72 [00:00<00:00, 300.29it/s, loss=0.00027, lr=0.000136] \n",
      "100%|██████████| 72/72 [00:00<00:00, 327.62it/s, loss=0.000267, lr=0.000126]\n",
      "100%|██████████| 72/72 [00:00<00:00, 312.82it/s, loss=0.000265, lr=0.000118]\n",
      "100%|██████████| 72/72 [00:00<00:00, 313.21it/s, loss=0.000263, lr=0.000109]\n",
      "100%|██████████| 72/72 [00:00<00:00, 323.68it/s, loss=0.000261, lr=0.000102]\n",
      "100%|██████████| 72/72 [00:00<00:00, 327.27it/s, loss=0.000259, lr=9.48e-5]\n",
      "100%|██████████| 72/72 [00:00<00:00, 313.36it/s, loss=0.000258, lr=8.82e-5]\n",
      "100%|██████████| 72/72 [00:00<00:00, 313.45it/s, loss=0.000256, lr=8.21e-5]\n",
      "100%|██████████| 72/72 [00:00<00:00, 313.04it/s, loss=0.000255, lr=7.64e-5]\n",
      "100%|██████████| 72/72 [00:00<00:00, 313.07it/s, loss=0.000254, lr=7.11e-5]\n",
      "100%|██████████| 72/72 [00:00<00:00, 299.89it/s, loss=0.000252, lr=6.61e-5]\n",
      "100%|██████████| 72/72 [00:00<00:00, 312.07it/s, loss=0.000251, lr=6.15e-5]\n",
      "100%|██████████| 72/72 [00:00<00:00, 334.82it/s, loss=0.00025, lr=5.73e-5] \n",
      "100%|██████████| 72/72 [00:00<00:00, 313.00it/s, loss=0.000249, lr=5.33e-5]\n",
      "100%|██████████| 72/72 [00:00<00:00, 320.64it/s, loss=0.000247, lr=4.96e-5]\n",
      "100%|██████████| 72/72 [00:00<00:00, 301.96it/s, loss=0.000246, lr=4.61e-5]\n",
      "100%|██████████| 72/72 [00:00<00:00, 313.14it/s, loss=0.000245, lr=4.29e-5]\n",
      "100%|██████████| 72/72 [00:00<00:00, 315.86it/s, loss=0.000245, lr=3.99e-5]\n",
      "100%|██████████| 72/72 [00:00<00:00, 312.71it/s, loss=0.000244, lr=3.72e-5]\n",
      "100%|██████████| 72/72 [00:00<00:00, 321.18it/s, loss=0.000243, lr=3.46e-5]\n",
      "100%|██████████| 72/72 [00:00<00:00, 300.26it/s, loss=0.000242, lr=3.22e-5]\n",
      "100%|██████████| 72/72 [00:00<00:00, 321.65it/s, loss=0.00024, lr=2.99e-5] \n",
      "100%|██████████| 72/72 [00:00<00:00, 288.13it/s, loss=0.00024, lr=2.79e-5] \n",
      "100%|██████████| 72/72 [00:00<00:00, 300.14it/s, loss=0.000239, lr=2.59e-5]\n",
      "100%|██████████| 72/72 [00:00<00:00, 299.50it/s, loss=0.000238, lr=2.41e-5]\n",
      "100%|██████████| 72/72 [00:00<00:00, 313.21it/s, loss=0.000238, lr=2.24e-5]\n",
      "100%|██████████| 72/72 [00:00<00:00, 327.60it/s, loss=0.000237, lr=2.09e-5]\n",
      "100%|██████████| 72/72 [00:00<00:00, 313.19it/s, loss=0.000237, lr=1.94e-5]\n",
      "100%|██████████| 72/72 [00:00<00:00, 312.92it/s, loss=0.000236, lr=1.81e-5]\n",
      "100%|██████████| 72/72 [00:00<00:00, 323.96it/s, loss=0.000236, lr=1.68e-5]\n",
      "100%|██████████| 72/72 [00:00<00:00, 302.65it/s, loss=0.000235, lr=1.57e-5]\n",
      "100%|██████████| 72/72 [00:00<00:00, 312.91it/s, loss=0.000235, lr=1.46e-5]\n",
      "100%|██████████| 72/72 [00:00<00:00, 312.95it/s, loss=0.000235, lr=1.36e-5]\n",
      "100%|██████████| 72/72 [00:00<00:00, 310.27it/s, loss=0.000234, lr=1.26e-5]\n",
      "100%|██████████| 72/72 [00:00<00:00, 312.81it/s, loss=0.000234, lr=1.17e-5]\n",
      "100%|██████████| 72/72 [00:00<00:00, 300.02it/s, loss=0.000234, lr=1.09e-5]\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T09:11:01.741585Z",
     "start_time": "2025-03-02T09:11:01.684046Z"
    }
   },
   "cell_type": "code",
   "source": "torch.save(mlp.state_dict(), 'models/torque_target_deterministic_mlp.pt')",
   "id": "41add3df5d7ed247",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T09:13:16.128050Z",
     "start_time": "2025-03-02T09:13:16.041196Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mlp.load_state_dict(torch.load('models/torque_target_deterministic_mlp.pt', weights_only=True))\n",
    "mlp.eval()\n",
    "for i in range(10):\n",
    "    x_test = train_x_1[i].unsqueeze(0)\n",
    "    y_test = train_y_1[i].unsqueeze(0)\n",
    "    print(y_test[0].item(), mlp(x_test))"
   ],
   "id": "ff699d2886657896",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.2830093502998352 tensor([[-0.2956]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "-1.267451524734497 tensor([[-1.2753]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "-0.4435439705848694 tensor([[-0.4572]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "-0.3035033643245697 tensor([[-0.3209]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "-0.5718362927436829 tensor([[-0.5891]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "-0.8585125803947449 tensor([[-0.8682]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "1.492055892944336 tensor([[1.4708]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "-0.8199540972709656 tensor([[-0.8420]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "1.0689382553100586 tensor([[1.0729]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "2.143380641937256 tensor([[2.1397]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "execution_count": 32
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
