{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T00:16:00.572664Z",
     "start_time": "2025-03-04T00:15:58.902852Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from kan import KAN as PyKAN\n",
    "from torch import nn, optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "from efficient_kan.kan import KAN as EffKAN\n",
    "from ptflops import get_model_complexity_info\n",
    "\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ],
   "id": "eb0c719fbbf47cac",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Torque target Stochastic Regression\n",
    "\n",
    "In this notebook we're going to train a `PyKAN`, an `EfficientKAN`, and a `MLP` to learn a function that maps each set of input features to its own probability distribution.\n",
    "\n",
    "We assume that the underlying process has many small, independent disturbances. Thus, Leveraging the Central limit theorem, we can say that the error between the model's prediction and **the actual observed value is likely to be normal**."
   ],
   "id": "61e0637cf4254aef"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load dataset",
   "id": "f189be38c359f66"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "USE_SYNTHETIC_DATASET = False  # Generated with 2-Synthetic_Dataset.ipynb\n",
    "\n",
    "if USE_SYNTHETIC_DATASET:\n",
    "    df = pd.read_csv('../dataset/3d_normal_std.csv')\n",
    "    df_normalized = (df - df.mean()) / df.std()\n",
    "    df_x_normalized = df_normalized.drop(columns=['label'])\n",
    "    df_y_normalized = df_normalized['label']\n",
    "else:\n",
    "    df_x = pd.read_csv('../dataset/2-regression/X.csv').drop(columns=['id'])\n",
    "    df_y = pd.read_csv('../dataset/2-regression/y.csv').drop(columns=['id', 'faulty'])\n",
    "    df_y['trq_target'] = df_x['trq_measured'] / (df_y['trq_margin'] / 100 + 1)\n",
    "    df_x_normalized = (df_x - df_x.mean()) / df_x.std()\n",
    "    df_y_normalized = (df_y['trq_target'] - df_y['trq_target'].mean()) / df_y['trq_target'].std()\n",
    "    df_x_normalized.drop(columns=['trq_measured'], inplace=True)\n",
    "\n",
    "dataset_x = torch.tensor(df_x_normalized.values, dtype=torch.float32, device=device)\n",
    "dataset_y = torch.tensor(df_y_normalized.values, dtype=torch.float32, device=device).unsqueeze(1)\n",
    "assert (dataset_x.shape[0] == dataset_y.shape[0])"
   ],
   "id": "7737001342829f2f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "dataset_size = dataset_x.shape[0]\n",
    "random_indices = np.random.choice(dataset_size, size=dataset_size, replace=False)\n",
    "\n",
    "# Train set = 10% Data set\n",
    "train_x = dataset_x[random_indices[:int(dataset_size * 0.1)]]\n",
    "train_y = dataset_y[random_indices[:int(dataset_size * 0.1)]]\n",
    "\n",
    "# Valid set = 10% Data set\n",
    "valid_x = dataset_x[random_indices[int(dataset_size * 0.1):int(dataset_size * 0.2)]]\n",
    "valid_y = dataset_y[random_indices[int(dataset_size * 0.1):int(dataset_size * 0.2)]]\n",
    "\n",
    "# Test set = 20% Data set\n",
    "test_x = dataset_x[random_indices[int(dataset_size * 0.2):int(dataset_size * 0.4)]]\n",
    "test_y = dataset_y[random_indices[int(dataset_size * 0.2):int(dataset_size * 0.4)]]"
   ],
   "id": "ec9cec0d85c0230e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define the train() and test() functions",
   "id": "5700e0d8e8693dbe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def train(model, optimizer, epochs, batch_size=8192):\n",
    "    criterion = nn.GaussianNLLLoss(reduction='mean')\n",
    "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.97)\n",
    "    train_losses = []\n",
    "    validation_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        epoch_train_losses = []\n",
    "        epoch_validation_losses = []\n",
    "\n",
    "        # Training\n",
    "        model.train()\n",
    "        with tqdm(range(train_x.size(0) // batch_size)) as pbar:\n",
    "            for i in pbar:\n",
    "                x = train_x[i * batch_size:(i + 1) * batch_size]\n",
    "                y = train_y[i * batch_size:(i + 1) * batch_size]\n",
    "                optimizer.zero_grad()\n",
    "                mu, log_var = model(x)\n",
    "                loss = criterion(mu, y.squeeze(), torch.exp(log_var))\n",
    "                loss.backward()\n",
    "                epoch_train_losses.append(loss.item())\n",
    "                optimizer.step(closure=lambda: loss)\n",
    "                pbar.set_postfix(loss=loss.item(), lr=optimizer.param_groups[0]['lr'])\n",
    "        scheduler.step()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        for i in range(valid_x.size(0) // batch_size):\n",
    "            x = valid_x[i * batch_size:(i + 1) * batch_size]\n",
    "            y = valid_y[i * batch_size:(i + 1) * batch_size]\n",
    "            mu, log_var = model(x)\n",
    "            loss = criterion(mu, y.squeeze(), torch.exp(log_var))\n",
    "            loss.backward()\n",
    "            epoch_validation_losses.append(loss.item())\n",
    "\n",
    "        train_losses.append(np.mean(epoch_train_losses))\n",
    "        validation_losses.append(np.mean(epoch_validation_losses))\n",
    "\n",
    "    # Plot losses\n",
    "    plt.figure(figsize=(24, 8))\n",
    "    plt.plot(train_losses, label='Training loss')\n",
    "    plt.plot(validation_losses, label='Validation loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "id": "b46d3162d5fa44e7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T23:05:27.656716Z",
     "start_time": "2025-03-03T23:05:27.618157Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test(model) -> float:\n",
    "    model.eval()\n",
    "    criterion = nn.GaussianNLLLoss(reduction='mean')\n",
    "    test_losses = []\n",
    "    vars=[]\n",
    "    for i in range(valid_x.size(0) // 8192):\n",
    "        x = test_x[i * 8192:(i + 1) * 8192]\n",
    "        y = test_y[i * 8192:(i + 1) * 8192]\n",
    "        mu, log_var = model(x)\n",
    "        loss = criterion(mu, y.squeeze(), torch.exp(log_var))\n",
    "        vars.extend(torch.exp(log_var).detach().cpu().numpy().tolist())\n",
    "        loss.backward()\n",
    "        test_losses.append(loss.item())\n",
    "    print(sum(vars)/len(vars))\n",
    "    return sum(test_losses) / len(test_losses)"
   ],
   "id": "5f706a2823f68142",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Train the PyKAN",
   "id": "8e07b9b7f551b186"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class Py_KAN(nn.Module):\n",
    "    def __init__(self, layers, grid_size=8):\n",
    "        super(Py_KAN, self).__init__()\n",
    "        self.model = PyKAN(width=layers, grid=grid_size, k=3, device=device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        mu = x[:, 0]\n",
    "        var = x[:, 1]\n",
    "        return mu, var"
   ],
   "id": "87e6612421dd5155"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "pyKAN = Py_KAN(layers=[[3, 0], [1, 0], [2, 0]], grid_size=2)",
   "id": "a5e418b32478f320"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "pyKAN.model = PyKAN.loadckpt('models/torque_target_stochastic_pykan.pt')",
   "id": "71072b2a044ede43"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "train(pyKAN, optim.Adam(pyKAN.parameters(), lr=0.05), epochs=300, batch_size=4096)",
   "id": "b960ca6448de1b13"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "test(pyKAN)",
   "id": "74a596ba44a9744c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "pyKAN.model.saveckpt('models/torque_target_stochastic_pykan.pt')",
   "id": "aa93874da67ae268"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "pyKAN.model.plot(scale=2, in_vars=['x1', 'x2', 'x3'], out_vars=['μ', 'σ'], varscale=0.75)",
   "id": "4aef1ce3e47df2eb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Train the EfficientKAN",
   "id": "440f5dc99868cb5a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class Efficient_KAN(nn.Module):\n",
    "    def __init__(self, layers, grid_size=8):\n",
    "        super(Efficient_KAN, self).__init__()\n",
    "        self.model = EffKAN(layers,\n",
    "                            grid_size=grid_size,\n",
    "                            # grid_eps=1,\n",
    "                            # scale_base=0,\n",
    "                            # sp_trainable=False,\n",
    "                            # sb_trainable=False,\n",
    "                            # enable_standalone_scale_spline=False\n",
    "                            ).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = x / dataset_size * 2 - 1\n",
    "        # x = x.view(-1, self.layers[0])\n",
    "        x = self.model(x)\n",
    "        mu = x[:, 0]\n",
    "        var = x[:, 1]  #F.softplus(x[:, 1]) + 1e-6\n",
    "        return mu, var"
   ],
   "id": "4f51b0c001b2204f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "efficientKAN = Efficient_KAN(layers=[6, 1, 2], grid_size=2)",
   "id": "15747ef41d3cfac8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "efficientKAN.model.load_state_dict(torch.load('models/torque_target_stochastic_effkan.pt', weights_only=True))",
   "id": "9a320f2646998008"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "train(efficientKAN, optim.Adam(efficientKAN.parameters(), lr=0.02), epochs=150)",
   "id": "bce3e6d9a8b0a5bd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "test(efficientKAN)",
   "id": "d4fa11d68e9fbb17"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "torch.save(efficientKAN.model.state_dict(), 'models/torque_target_stochastic_effkan.pt')",
   "id": "501fe8a4802a52c4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def plot_spline(model: EffKAN, x_range, scale=1, resolution=50):\n",
    "    base_colors = [(1, 0, 0), (0, 1, 0), (0, 0, 1)]\n",
    "\n",
    "    def random_color():\n",
    "        return random.random(), random.random(), random.random()\n",
    "\n",
    "    colors = [base_colors[x] if x < len(base_colors) else random_color()\n",
    "              for x in range(max(map(lambda l: l.in_features, model.layers)))]\n",
    "    for layer in reversed(model.layers):\n",
    "        fig, axes = plt.subplots(1, layer.in_features * layer.out_features,\n",
    "                                 figsize=(2 * scale * layer.in_features * layer.out_features, 2 * scale))\n",
    "        for i in range(layer.in_features):\n",
    "            for j in range(layer.out_features):\n",
    "                x_vals = torch.linspace(x_range[0], x_range[1], resolution)\n",
    "\n",
    "                # B-Splines\n",
    "                if len(layer.grid) <= j:\n",
    "                    continue\n",
    "                grid = layer.grid[j, :].unsqueeze(0).to(device)  # The knots\n",
    "                x = x_vals.unsqueeze(-1).unsqueeze(-1).to(device)\n",
    "                bases = ((x >= grid[:, :-1]) & (x < grid[:, 1:])).to(x.dtype)  # Determine the interval for each point\n",
    "                for k in range(1, layer.spline_order + 1):\n",
    "                    bases = (\n",
    "                                    (x - grid[:, : -(k + 1)])\n",
    "                                    / (grid[:, k:-1] - grid[:, : -(k + 1)])\n",
    "                                    * bases[:, :, :-1]\n",
    "                            ) + (\n",
    "                                    (grid[:, k + 1:] - x)\n",
    "                                    / (grid[:, k + 1:] - grid[:, 1:(-k)])\n",
    "                                    * bases[:, :, 1:]\n",
    "                            )\n",
    "\n",
    "                y_vals = F.linear(bases.squeeze(), layer.scaled_spline_weight[j, i]).to(device)\n",
    "                y_vals += (layer.base_activation(x_vals).to(device) * layer.base_weight[j, i].to(device))\n",
    "\n",
    "                alpha = math.tanh(abs(3 * layer.spline_scaler.view(layer.out_features, -1)[j, i].item()))\n",
    "                if type(axes) is np.ndarray:\n",
    "                    axes[i * layer.out_features + j].plot(x_vals.cpu().detach().numpy(), y_vals.cpu().detach().numpy(),\n",
    "                                                          alpha=alpha, color=colors[i])\n",
    "                    axes[i * layer.out_features + j].grid(True)\n",
    "                else:\n",
    "                    axes.plot(x_vals, y_vals, alpha=alpha, color=colors[i])\n",
    "                    axes.grid(True)\n",
    "\n",
    "    # plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "13e622d1019b6831"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "plot_spline(efficientKAN.model, [-3, 3], scale=1.75, resolution=100)",
   "id": "bab31a183cd14dae"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Train the MLP",
   "id": "af7403e72078089a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, layers_size, deterministic=False):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers_size = layers_size\n",
    "        layers = []\n",
    "        for i in range(len(layers_size) - 1):\n",
    "            layers.append(nn.Linear(layers_size[i], layers_size[i + 1]))\n",
    "            if i < len(layers_size) - 2:  # Add activation for all layers except the last one\n",
    "                layers.append(nn.Sigmoid())\n",
    "        self.model = nn.Sequential(*layers)\n",
    "        self.deterministic = deterministic\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.model(x)\n",
    "        if self.deterministic:\n",
    "            return output\n",
    "        else:\n",
    "            mu = output[:, 0]\n",
    "            var = output[:, 1]\n",
    "            return mu, var"
   ],
   "id": "9be1593fc064efea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "mlp = MLP([6, 256, 256, 2], deterministic=False).to(device)",
   "id": "740911233d6cb91c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "mlp.load_state_dict(torch.load('models/torque_target_stochastic_mlp.pt', weights_only=True))",
   "id": "7183ed1204e8f226"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "train(mlp, optim.Adam(mlp.parameters(), lr=.01), epochs=300)",
   "id": "89bcfa04ae05467e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "torch.save(mlp.state_dict(), 'models/torque_target_stochastic_mlp.pt')",
   "id": "3063fd46882bf483"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T23:05:31.445442Z",
     "start_time": "2025-03-03T23:05:31.170188Z"
    }
   },
   "cell_type": "code",
   "source": "test(mlp)",
   "id": "ef9efe8ba2564f45",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2655238893217242e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-5.274217393663195"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T00:16:12.025997Z",
     "start_time": "2025-03-04T00:16:12.002533Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with torch.cuda.device(0):\n",
    "    flops, params = get_model_complexity_info(mlp, (6,), as_strings=True)\n",
    "    print(f\"FLOPs: {flops}\")\n",
    "    print(f\"Params: {params}\")"
   ],
   "id": "2704ddd49638e09d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  68.1 k, 100.000% Params, 68.1 KMac, 100.000% MACs, \n",
      "  (model): Sequential(\n",
      "    68.1 k, 100.000% Params, 68.1 KMac, 100.000% MACs, \n",
      "    (0): Linear(1.79 k, 2.632% Params, 1.79 KMac, 2.632% MACs, in_features=6, out_features=256, bias=True)\n",
      "    (1): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "    (2): Linear(65.79 k, 96.614% Params, 65.79 KMac, 96.614% MACs, in_features=256, out_features=256, bias=True)\n",
      "    (3): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "    (4): Linear(514, 0.755% Params, 514.0 Mac, 0.755% MACs, in_features=256, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "FLOPs: 68.1 KMac\n",
      "Params: 68.1 k\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def plot_mlp(net: MLP):\n",
    "    layers = [net.model[0].in_features]\n",
    "    linears = list(filter(lambda l: type(l) == torch.nn.modules.linear.Linear, mlp.model))\n",
    "    for l in linears:\n",
    "        layers.append(l.out_features)\n",
    "    # layers = [6, 50, 50, 2]\n",
    "    G = nx.Graph()\n",
    "    pos = {}\n",
    "    node_count = 0\n",
    "    layer_gap = 5\n",
    "    node_gap = 1\n",
    "    max_layer = max(layers)\n",
    "\n",
    "    for i, layer_size in enumerate(layers):\n",
    "        delta = max_layer - layer_size\n",
    "        for j in range(layer_size):\n",
    "            G.add_node(node_count)\n",
    "            pos[node_count] = (i * layer_gap, (j + delta // 2) * node_gap)\n",
    "            if i > 0:\n",
    "                for k in range(layers[i - 1]):\n",
    "                    G.add_edge(node_count - layers[i - 1] + k - j, node_count,\n",
    "                               weight=linears[i - 1].weight[j, k].item())\n",
    "            node_count += 1\n",
    "\n",
    "    weights = [G[u][v]['weight'] for u, v in G.edges()]\n",
    "    plt.figure(1, figsize=(16, 4))\n",
    "    plt.hist(weights, bins='auto', edgecolor='black')\n",
    "    plt.grid()\n",
    "    plt.title('Weights distribution')\n",
    "    plt.figure(3, figsize=(85, 100))\n",
    "    nx.draw(G, pos, with_labels=True, node_size=150, node_color=\"skyblue\", edge_cmap=plt.colormaps['PiYG'],\n",
    "            edge_color=weights, edge_vmin=-0.5, edge_vmax=0.5, font_size=10, width=5)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_mlp(mlp)\n"
   ],
   "id": "fbf9f96441781d91"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
